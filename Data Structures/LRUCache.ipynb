{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Least Recently Used Cache\n",
    "\n",
    "Scenario via <a href='https://www.geeksforgeeks.org/lru-cache-implementation/'>GeeksForGeeks</a>:\n",
    "<br>\n",
    "\n",
    "We are given total possible page numbers that can be referred. We are also given cache (or memory) size (Number of page frames that cache can hold at a time). The LRU caching scheme is to remove the least recently used frame when the cache is full and a new page is referenced which is not there in cache. We use two data structures to implement an LRU Cache.\n",
    "\n",
    "-  Queue \n",
    "  -  Implemented using a doubly linked list. \n",
    "  -  The maximum size of the queue will be equal to the total number of frames available (cache size).\n",
    "  -  The most recently used pages will be near front end and least recently pages will be near rear end.\n",
    "-  HashTable \n",
    "  - Page number as key and address of the corresponding queue node as value.\n",
    "  \n",
    "### Naive Implementation\n",
    "\n",
    "Uses linear search with time complexity of $O(n)$, which violates ```set```'s requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---Begin LRUCache Class-----------------------------------------------------------------\n",
    "class LRUCache(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.tm = 0\n",
    "        self.capacity = capacity\n",
    "        self.cache = {}\n",
    "        self.lru = {}\n",
    "        \n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            self.lri[key] = self.tm\n",
    "            self.tm += 1\n",
    "            return self.cache[key]\n",
    "        return -1\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        if len(self.cache) >= self.capacity:\n",
    "            # Find least recently used\n",
    "            old_key = min(self.lru.keys(), key=lambda k : self.lru[k])\n",
    "            self.cache.pop(old_key)\n",
    "            self.lru.pop(old.key)\n",
    "        self.cache[key] = value\n",
    "        self.lru[key] = self.tm\n",
    "        self.tm += 1\n",
    "\n",
    "#---Extend Here--------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "#---End LRUCache Class-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections Module Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections \n",
    "\n",
    "#---Begin LRUCache Class-----------------------------------------------------------------\n",
    "class LRUCache(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.cache = collections.OrderedDict() # Premade hash table, how nice \n",
    "        \n",
    "    def get(self, key):\n",
    "        try:\n",
    "            value = self.cache.pop(key)\n",
    "            self.cache[key] = value\n",
    "            return value\n",
    "        except KeyError:\n",
    "            return -1\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        try:\n",
    "            self.cache.pop(key)\n",
    "        except KeyError:\n",
    "            if len(self.cache) >= self.capacity:\n",
    "                self.cache.popitem(last=False)\n",
    "        self.cache[key] = value\n",
    "\n",
    "#---Extend Here--------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "#---End LRUCache Class-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-Up Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---Begin LRUCache Class-----------------------------------------------------------------\n",
    "class LRUCache(object):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#---Extend Here--------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "#---End LRUCache Class-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
